import streamlit as st
import jieba
from collections import Counter
import pandas as pd

# ---------------------- é…ç½®é¡¹æŠ½ç¦»ï¼ˆæ›´æ˜“ç»´æŠ¤ï¼‰ ----------------------
# é¡µé¢åŸºç¡€é…ç½®
st.set_page_config(page_title="ç®€æ˜“æ–‡æœ¬åˆ†æå·¥å…·", page_icon="ğŸ“", layout="centered")
# æ‰©å±•åœç”¨è¯è¡¨ï¼ˆæå‡è¿‡æ»¤æ•ˆæœï¼‰
STOP_WORDS = {
    "çš„", "äº†", "æ˜¯", "æˆ‘", "ä½ ", "ä»–", "å¥¹", "å®ƒ",
    "åœ¨", "å’Œ", "æœ‰", "å°±", "éƒ½", "è¿™", "é‚£", "å…¶",
    "åŠ", "ä¸", "äº", "å¯¹", "å“¦", "å‘¢", "å•Š", "å§",
    "å—", "å‘€", "è€Œ", "ä¹Ÿ", "è¿˜", "å°†", "ä¼š", "è¦"
}

# ---------------------- æ ¸å¿ƒåŠŸèƒ½å‡½æ•°å°è£…ï¼ˆç»“æ„æ›´æ¸…æ™°ï¼Œç¼©è¿›æ­£ç¡®ï¼‰ ----------------------
def calculate_text_stats(input_text):
    """è®¡ç®—æ–‡æœ¬åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"""
    # å‡½æ•°å†…ä»£ç ç»Ÿä¸€ç¼©è¿›4ä¸ªç©ºæ ¼
    total_with_space = len(input_text)
    # å»é™¤ç©ºæ ¼ã€æ¢è¡Œåçš„çº¯æ–‡æœ¬å­—ç¬¦æ•°
    pure_text = input_text.replace(" ", "").replace("\n", "")
    total_without_space = len(pure_text)
    # è¿”å›ç»Ÿè®¡ç»“æœ
    return {
        "å«ç©ºæ ¼æ¢è¡Œæ€»å­—ç¬¦æ•°": total_with_space,
        "æ— ç©ºæ ¼æ¢è¡Œçº¯å­—ç¬¦æ•°": total_without_space,
        "çº¯æ–‡æœ¬å†…å®¹": pure_text
    }

def get_top_keywords(pure_text, top_n=10):
    """æå–æ–‡æœ¬é«˜é¢‘å…³é”®è¯ï¼Œè¿”å›DataFrame"""
    # å‡½æ•°å†…ä»£ç ç»Ÿä¸€ç¼©è¿›4ä¸ªç©ºæ ¼
    # ä¸­æ–‡åˆ†è¯
    word_list = jieba.lcut(pure_text)
    # è¿‡æ»¤æ— æ„ä¹‰è¯æ±‡ï¼ˆåœç”¨è¯ + å•å­—ï¼‰
    valid_words = [
        word for word in word_list
        if word not in STOP_WORDS and len(word) > 1
    ]
    # ç»Ÿè®¡è¯é¢‘å¹¶å¤„ç†ç©ºå€¼
    if not valid_words:
        # æ— æœ‰æ•ˆå…³é”®è¯æ—¶è¿”å›ç©ºDataFrameï¼ˆé¿å…æŠ¥é”™ï¼‰
        return pd.DataFrame(columns=["å…³é”®è¯", "å‡ºç°æ¬¡æ•°"])
    word_count = Counter(valid_words)
    top_keywords = word_count.most_common(top_n)
    # è½¬æ¢ä¸ºDataFrameè¿”å›
    return pd.DataFrame(top_keywords, columns=["å…³é”®è¯", "å‡ºç°æ¬¡æ•°"])

# ---------------------- é¡µé¢å¸ƒå±€ä¸äº¤äº’ï¼ˆæ— å˜é‡æœªå®šä¹‰é”™è¯¯ï¼‰ ----------------------
# é¡µé¢æ ‡é¢˜ä¸æè¿°
st.title("ğŸ“ ç®€æ˜“æ–‡æœ¬åˆ†æWebåº”ç”¨")
st.divider()
st.caption("æ”¯æŒä¸­æ–‡æ–‡æœ¬å­—ç¬¦ç»Ÿè®¡ä¸é«˜é¢‘å…³é”®è¯æå–ï¼Œè½»é‡é«˜æ•ˆï¼")

# æ–‡æœ¬è¾“å…¥åŒºåŸŸ
with st.container(border=True):
    user_input = st.text_area(
        label="è¯·è¾“å…¥å¾…åˆ†æçš„æ–‡æœ¬å†…å®¹",
        height=200,
        placeholder="ç¤ºä¾‹ï¼šä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºé—¨æ•£æ­¥ï¼Œå¤©æ°”å¥½çš„æ—¶å€™ï¼Œå¿ƒæƒ…ä¹Ÿä¼šè·Ÿç€å˜å¥½...",
        label_visibility="collapsed"
    )

# åˆ†ææŒ‰é’®
analyze_btn = st.button("ğŸš€ å¼€å§‹æ–‡æœ¬åˆ†æ", use_container_width=True)

# åˆ†æé€»è¾‘æ‰§è¡Œ
if analyze_btn:
    # æ ¡éªŒè¾“å…¥æ˜¯å¦ä¸ºç©º
    if not user_input.strip():
        st.warning("âš ï¸ è¯·å…ˆè¾“å…¥æœ‰æ•ˆæ–‡æœ¬å†è¿›è¡Œåˆ†æå“¦ï¼")
    else:
        # 1. è®¡ç®—æ–‡æœ¬ç»Ÿè®¡ä¿¡æ¯
        text_stats = calculate_text_stats(user_input)
        # 2. æå–é«˜é¢‘å…³é”®è¯
        keyword_df = get_top_keywords(text_stats["çº¯æ–‡æœ¬å†…å®¹"])

        # 3. å±•ç¤ºåˆ†æç»“æœï¼ˆå…ˆå®šä¹‰åˆ—å˜é‡ï¼Œå†ä½¿ç”¨withï¼‰
        st.success("âœ… æ–‡æœ¬åˆ†æå®Œæˆï¼ä»¥ä¸‹æ˜¯è¯¦ç»†ç»“æœï¼š")
        st.divider()

        # åŸºç¡€ç»Ÿè®¡ä¿¡æ¯ + é«˜é¢‘å…³é”®è¯ï¼ˆåˆ†æ å±•ç¤ºï¼Œæ— col2æœªå®šä¹‰é”™è¯¯ï¼‰
        col1, col2 = st.columns(2)  # å…ˆåˆ›å»ºåˆ—å˜é‡

        with col1:
            st.subheader("ğŸ“Š åŸºç¡€å­—ç¬¦ç»Ÿè®¡")
            st.metric(label="å«ç©ºæ ¼æ¢è¡Œæ€»å­—ç¬¦æ•°", value=text_stats["å«ç©ºæ ¼æ¢è¡Œæ€»å­—ç¬¦æ•°"])
            st.metric(label="æ— ç©ºæ ¼æ¢è¡Œçº¯å­—ç¬¦æ•°", value=text_stats["æ— ç©ºæ ¼æ¢è¡Œçº¯å­—ç¬¦æ•°"])

        with col2:
            st.subheader("ğŸ”¤ é«˜é¢‘å…³é”®è¯TOP10")
            # ç›´æ¥å±•ç¤ºDataFrameï¼ˆæ— éœ€é¢å¤–åˆ¤æ–­ï¼Œå·²å¤„ç†ç©ºå€¼ï¼‰
            st.dataframe(keyword_df, index=False, use_container_width=True)
            # æ— å…³é”®è¯æ—¶ç»™å‡ºæç¤º
            if keyword_df.empty:
                st.info("ğŸ“Œ æœªæå–åˆ°æœ‰æ•ˆå…³é”®è¯ï¼ˆæ–‡æœ¬è¿‡çŸ­æˆ–æ— æœ‰æ•ˆè¯æ±‡ï¼‰")