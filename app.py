import streamlit as st
import jieba
from collections import Counter
import pandas as pd

# ---------------------- é…ç½®é¡¹æŠ½ç¦»ï¼ˆæ›´æ˜“ç»´æŠ¤ï¼‰ ----------------------
# é¡µé¢åŸºç¡€é…ç½®
st.set_page_config(page_title="ç®€æ˜“æ–‡æœ¬åˆ†æå·¥å…·", page_icon="ğŸ“", layout="centered")
# æ‰©å±•åœç”¨è¯è¡¨ï¼ˆæå‡è¿‡æ»¤æ•ˆæœï¼‰
STOP_WORDS = {
    "çš„", "äº†", "æ˜¯", "æˆ‘", "ä½ ", "ä»–", "å¥¹", "å®ƒ",
    "åœ¨", "å’Œ", "æœ‰", "å°±", "éƒ½", "è¿™", "é‚£", "å…¶",
    "åŠ", "ä¸", "äº", "å¯¹", "å“¦", "å‘¢", "å•Š", "å§",
    "å—", "å‘€", "è€Œ", "ä¹Ÿ", "è¿˜", "å°†", "ä¼š", "è¦"
}

# ---------------------- æ ¸å¿ƒåŠŸèƒ½å‡½æ•°å°è£…ï¼ˆç»“æ„æ›´æ¸…æ™°ï¼‰ ----------------------
def calculate_text_stats(input_text):
    """è®¡ç®—æ–‡æœ¬åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"""
    # å«ç©ºæ ¼å’Œæ¢è¡Œçš„æ€»å­—ç¬¦æ•°
    total_with_space = len(input_text)
    # å»é™¤ç©ºæ ¼ã€æ¢è¡Œåçš„çº¯æ–‡æœ¬å­—ç¬¦æ•°
    pure_text = input_text.replace(" ", "").replace("\n", "")
    total_without_space = len(pure_text)
    # è¿”å›ç»Ÿè®¡ç»“æœ
    return {
        "å«ç©ºæ ¼æ¢è¡Œæ€»å­—ç¬¦æ•°": total_with_space,
        "æ— ç©ºæ ¼æ¢è¡Œçº¯å­—ç¬¦æ•°": total_without_space,
        "çº¯æ–‡æœ¬å†…å®¹": pure_text
    }

def get_top_keywords(pure_text, top_n=10):
    """æå–æ–‡æœ¬é«˜é¢‘å…³é”®è¯"""
    # ä¸­æ–‡åˆ†è¯
    word_list = jieba.lcut(pure_text)
    # è¿‡æ»¤æ— æ„ä¹‰è¯æ±‡ï¼ˆåœç”¨è¯ + å•å­—ï¼‰
    valid_words = [
        word for word in word_list
        if word not in STOP_WORDS and len(word) > 1
    ]
    # ç»Ÿè®¡è¯é¢‘å¹¶å–å‰Nä¸ª
    if not valid_words:
        return None
    word_count = Counter(valid_words)
    top_keywords = word_count.most_common(top_n)
    return top_keywords

# ---------------------- é¡µé¢å¸ƒå±€ä¸äº¤äº’ï¼ˆæ›´ç¾è§‚ç›´è§‚ï¼‰ ----------------------
# é¡µé¢æ ‡é¢˜ä¸æè¿°
st.title("ğŸ“ ç®€æ˜“æ–‡æœ¬åˆ†æWebåº”ç”¨")
st.divider()
st.caption("æ”¯æŒä¸­æ–‡æ–‡æœ¬å­—ç¬¦ç»Ÿè®¡ä¸é«˜é¢‘å…³é”®è¯æå–ï¼Œè½»é‡é«˜æ•ˆï¼")

# æ–‡æœ¬è¾“å…¥åŒºåŸŸ
with st.container(border=True):  # å¸¦è¾¹æ¡†å®¹å™¨ï¼Œè§†è§‰æ›´æ•´æ´
    user_input = st.text_area(
        label="è¯·è¾“å…¥å¾…åˆ†æçš„æ–‡æœ¬å†…å®¹",
        height=200,
        placeholder="ç¤ºä¾‹ï¼šä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºé—¨æ•£æ­¥ï¼Œå¤©æ°”å¥½çš„æ—¶å€™ï¼Œå¿ƒæƒ…ä¹Ÿä¼šè·Ÿç€å˜å¥½...",
        label_visibility="collapsed"  # éšè—æ ‡ç­¾ï¼Œæ›´ç®€æ´
    )

# åˆ†ææŒ‰é’®ï¼ˆç‹¬ç«‹ä¸€è¡Œï¼Œæ›´é†’ç›®ï¼‰
analyze_btn = st.button("ğŸš€ å¼€å§‹æ–‡æœ¬åˆ†æ", use_container_width=True)

# åˆ†æé€»è¾‘æ‰§è¡Œ
if analyze_btn:
    # æ ¡éªŒè¾“å…¥æ˜¯å¦ä¸ºç©º
    if not user_input.strip():
        st.warning("âš ï¸ è¯·å…ˆè¾“å…¥æœ‰æ•ˆæ–‡æœ¬å†è¿›è¡Œåˆ†æå“¦ï¼")
    else:
        # 1. è®¡ç®—æ–‡æœ¬ç»Ÿè®¡ä¿¡æ¯
        text_stats = calculate_text_stats(user_input)
        # 2. æå–é«˜é¢‘å…³é”®è¯
        top_keywords = get_top_keywords(text_stats["çº¯æ–‡æœ¬å†…å®¹"])

        # 3. å±•ç¤ºåˆ†æç»“æœï¼ˆåˆ†æ å¸ƒå±€ï¼Œæ›´æ¸…æ™°ï¼‰
        st.success("âœ… æ–‡æœ¬åˆ†æå®Œæˆï¼ä»¥ä¸‹æ˜¯è¯¦ç»†ç»“æœï¼š")
        st.divider()

        # åŸºç¡€ç»Ÿè®¡ä¿¡æ¯ï¼ˆå·¦ä¾§æ ï¼‰
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸ“Š åŸºç¡€å­—ç¬¦ç»Ÿè®¡")
            for key, value in text_stats.items():
                if key != "çº¯æ–‡æœ¬å†…å®¹":  # ä¸å±•ç¤ºçº¯æ–‡æœ¬å†…å®¹ï¼Œé¿å…å†—ä½™
                    st.metric(label=key, value=value)

        # é«˜é¢‘å…³é”®è¯ï¼ˆå³ä¾§æ ï¼‰
        with col2:
            st.subheader("ğŸ”¤ é«˜é¢‘å…³é”®è¯TOP10")
            if top_keywords:
                # è½¬æ¢ä¸ºDataFrameå±•ç¤ºï¼Œæ›´ç¾è§‚
                keyword_df = pd.DataFrame(
                    top_keywords,
                    columns=["å…³é”®è¯", "å‡ºç°æ¬¡æ•°"]
                )
                st.dataframe(keyword_df, index=False, use_container_width=True)
            else:
                st.info("ğŸ“Œ æœªæå–åˆ°æœ‰æ•ˆå…³é”®è¯ï¼ˆæ–‡æœ¬è¿‡çŸ­æˆ–æ— æœ‰æ•ˆè¯æ±‡ï¼‰")